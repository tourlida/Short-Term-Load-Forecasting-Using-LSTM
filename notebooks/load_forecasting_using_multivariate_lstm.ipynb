{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from joblib import dump\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_seasonal_comparison(test_index, ys_test_rescaled, predictions_rescaled):\n",
    "    \"\"\"\n",
    "    Plot the average actual and forecasted load for each season.\n",
    "\n",
    "    Parameters:\n",
    "    - test_index: Datetime index for the test data.\n",
    "    - ys_test_rescaled: Rescaled actual test values.\n",
    "    - predictions_rescaled: Rescaled forecasted values.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame to hold the test and prediction data\n",
    "    data = pd.DataFrame({\n",
    "        'Actual': ys_test_rescaled.flatten(),\n",
    "        'Predicted': predictions_rescaled.flatten()\n",
    "    }, index=test_index)\n",
    "    \n",
    "    # Add a 'Season' column to the DataFrame\n",
    "    data['Month'] = data.index.month\n",
    "    data['Season'] = data['Month'].apply(lambda x: (\n",
    "        'Winter' if x in [12, 1, 2] else\n",
    "        'Spring' if x in [3, 4, 5] else\n",
    "        'Summer' if x in [6, 7, 8] else\n",
    "        'Autumn'\n",
    "    ))\n",
    "    \n",
    "    # Group by season and calculate the mean for actual and predicted values\n",
    "    seasonal_data = data.groupby('Season').mean()\n",
    "    \n",
    "    # Plot the seasonal comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(seasonal_data.index, seasonal_data['Actual'], label='Actual Load', marker='o')\n",
    "    plt.plot(seasonal_data.index, seasonal_data['Predicted'], label='Forecasted Load', marker='o')\n",
    "    plt.xlabel('Season')\n",
    "    plt.ylabel('Average Load')\n",
    "    plt.title('Average Actual Load and Forecasted Load by Season')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly_comparison(test_index, ys_test_rescaled, predictions_rescaled):\n",
    "    \"\"\"\n",
    "    Plot the average actual and forecasted load by month.\n",
    "\n",
    "    Parameters:\n",
    "    - test_index: Datetime index for the test data.\n",
    "    - ys_test_rescaled: Rescaled actual test values.\n",
    "    - predictions_rescaled: Rescaled forecasted values.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame to hold the test and prediction data\n",
    "    data = pd.DataFrame({\n",
    "        'Actual': ys_test_rescaled.flatten(),\n",
    "        'Predicted': predictions_rescaled.flatten()\n",
    "    }, index=test_index)\n",
    "    \n",
    "    # Add a 'Month' column to the DataFrame\n",
    "    data['Month'] = data.index.month\n",
    "\n",
    "    # Group by month and calculate the mean for actual and predicted values\n",
    "    monthly_data = data.groupby('Month').mean()\n",
    "\n",
    "    # Create month labels corresponding to the months present in the dataset\n",
    "    month_labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    available_months = monthly_data.index\n",
    "    available_labels = [month_labels[month - 1] for month in available_months]\n",
    "\n",
    "    # Plot the monthly comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(monthly_data.index, monthly_data['Actual'], label='Actual Load', marker='o')\n",
    "    plt.plot(monthly_data.index, monthly_data['Predicted'], label='Forecasted Load', marker='o')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Average Load')\n",
    "    plt.title('Average Actual Load and Forecasted Load by Month')\n",
    "    plt.xticks(ticks=monthly_data.index, labels=available_labels)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weekday_comparison(test_index, ys_test_rescaled, predictions_rescaled):\n",
    "    \"\"\"\n",
    "    Plot the average actual and forecasted load by day of the week.\n",
    "\n",
    "    Parameters:\n",
    "    - test_index: Datetime index for the test data.\n",
    "    - ys_test_rescaled: Rescaled actual test values.\n",
    "    - predictions_rescaled: Rescaled forecasted values.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame to hold the test and prediction data\n",
    "    data = pd.DataFrame({\n",
    "        'Actual': ys_test_rescaled.flatten(),\n",
    "        'Predicted': predictions_rescaled.flatten()\n",
    "    }, index=test_index)\n",
    "    \n",
    "    # Add a 'DayOfWeek' column to the DataFrame\n",
    "    data['DayOfWeek'] = data.index.dayofweek\n",
    "\n",
    "    # Group by day of the week and calculate the mean for actual and predicted values\n",
    "    weekday_data = data.groupby('DayOfWeek').mean()\n",
    "\n",
    "    # Create day labels corresponding to the days of the week\n",
    "    day_labels = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    available_days = weekday_data.index\n",
    "    available_day_labels = [day_labels[day] for day in available_days]\n",
    "\n",
    "    # Plot the weekday comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(weekday_data.index, weekday_data['Actual'], label='Actual Load', marker='o')\n",
    "    plt.plot(weekday_data.index, weekday_data['Predicted'], label='Forecasted Load', marker='o')\n",
    "    plt.xlabel('Day of the Week')\n",
    "    plt.ylabel('Average Load')\n",
    "    plt.title('Average Actual Load and Forecasted Load by Day of the Week')\n",
    "    plt.xticks(ticks=weekday_data.index, labels=available_day_labels)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hourly_comparison(test_index, ys_test_rescaled, predictions_rescaled):\n",
    "    \"\"\"\n",
    "    Plot the average actual and forecasted load by hour of the day.\n",
    "\n",
    "    Parameters:\n",
    "    - test_index: Datetime index for the test data.\n",
    "    - ys_test_rescaled: Rescaled actual test values.\n",
    "    - predictions_rescaled: Rescaled forecasted values.\n",
    "    \"\"\"\n",
    "    # Create a DataFrame to hold the test and prediction data\n",
    "    data = pd.DataFrame({\n",
    "        'Actual': ys_test_rescaled.flatten(),\n",
    "        'Predicted': predictions_rescaled.flatten()\n",
    "    }, index=test_index)\n",
    "    \n",
    "    # Add an 'Hour' column to the DataFrame\n",
    "    data['Hour'] = data.index.hour\n",
    "\n",
    "    # Group by hour of the day and calculate the mean for actual and predicted values\n",
    "    hourly_data = data.groupby('Hour').mean()\n",
    "\n",
    "    # Create hour labels corresponding to the hours of the day\n",
    "    available_hours = hourly_data.index\n",
    "    available_hour_labels = [f'{hour}:00' for hour in available_hours]\n",
    "\n",
    "    # Plot the hourly comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(hourly_data.index, hourly_data['Actual'], label='Actual Load', marker='o')\n",
    "    plt.plot(hourly_data.index, hourly_data['Predicted'], label='Forecasted Load', marker='o')\n",
    "    plt.xlabel('Hour of the Day')\n",
    "    plt.ylabel('Average Load')\n",
    "    plt.title('Average Actual Load and Forecasted Load by Hour of the Day')\n",
    "    plt.xticks(ticks=hourly_data.index, labels=available_hour_labels)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_from_to(test_index, ys_test_rescaled, predictions_rescaled, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Plot the actual and forecasted load for a specified date range.\n",
    "\n",
    "    Parameters:\n",
    "    - test_index: Datetime index for the test data.\n",
    "    - ys_test_rescaled: Rescaled actual test values.\n",
    "    - predictions_rescaled: Rescaled forecasted values.\n",
    "    - start_date: Start date for the plot.\n",
    "    - end_date: End date for the plot.\n",
    "    \"\"\"\n",
    "    # Convert start_date and end_date to datetime if they are strings\n",
    "    if isinstance(start_date, str):\n",
    "        start_date = pd.to_datetime(start_date)\n",
    "    if isinstance(end_date, str):\n",
    "        end_date = pd.to_datetime(end_date)\n",
    "\n",
    "    # Create a boolean mask for the date range\n",
    "    mask = (test_index >= start_date) & (test_index <= end_date)\n",
    "\n",
    "    # Apply the mask to the test data and predictions\n",
    "    time_index = test_index[mask]\n",
    "    ys_test_range = ys_test_rescaled[mask]\n",
    "    predictions_range = predictions_rescaled[mask]\n",
    "\n",
    "    # Plotting the actual and forecasted load for the specified date range\n",
    "    plt.figure(figsize=(24, 5))\n",
    "    plt.plot(time_index, ys_test_range.flatten(), label='Actual Load')\n",
    "    plt.plot(time_index, predictions_range.flatten(), label='Forecasted Load')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Load')\n",
    "    plt.title(f'Actual Load and Forecasted Load from {start_date:%Y-%m-%d} to {end_date:%Y-%m-%d}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Customize x-axis to show date and day of the week\n",
    "    plt.xticks(ticks=time_index[::24], labels=[f\"{date:%Y-%m-%d}\\n{date:%A}\" for date in time_index[::24]], rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(test_index, ys_test_rescaled, predictions_rescaled, hours_to_plot=720):\n",
    "    \"\"\"\n",
    "    Plot the actual and forecasted load for the first month.\n",
    "\n",
    "    Parameters:\n",
    "    - test_index: Datetime index for the test data.\n",
    "    - ys_test_rescaled: Rescaled actual test values.\n",
    "    - predictions_rescaled: Rescaled forecasted values.\n",
    "    - hours_in_month: Number of hours to plot for the first month.\n",
    "    \"\"\"\n",
    "    # Adjust the test index to include only the first month of data\n",
    "    time_index = test_index[:hours_to_plot]\n",
    "    ys_test_first_month = ys_test_rescaled[:hours_to_plot]\n",
    "    predictions_first_month = predictions_rescaled[:hours_to_plot]\n",
    "\n",
    "    # Plotting the initial month of actual and forecasted load\n",
    "    plt.figure(figsize=(24, 5))\n",
    "    plt.plot(time_index, ys_test_first_month.flatten(), label='Actual Load')\n",
    "    plt.plot(time_index, predictions_first_month.flatten(), label='Forecasted Load')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Load')\n",
    "    plt.title('Actual Load and Forecasted Load for the First Month')\n",
    "    plt.legend()\n",
    "\n",
    "    # Customize x-axis to show date and day of the week\n",
    "    plt.xticks(ticks=time_index[::24], labels=[f\"{date:%Y-%m-%d}\\n{date:%A}\" for date in time_index[::24]], rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_model(xs_train, ys_train, model_config, num_target_features,path_to_save_model):\n",
    "    \"\"\"\n",
    "    Build, train, and evaluate an LSTM model.\n",
    "\n",
    "    Parameters:\n",
    "    - xs_train, ys_train: Training data.\n",
    "    - xs_test, ys_test: Test data.\n",
    "    - model_config: Dictionary containing LSTM layers configuration and other model parameters.\n",
    "    - scaler: Scaler used to scale data.\n",
    "    - num_target_features: Number of output features for the model.\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained LSTM model.\n",
    "    - history: Training history of the model.\n",
    "    - predictions_rescaled: Rescaled predictions.\n",
    "    - ys_test_rescaled: Rescaled actual values.\n",
    "    \"\"\"\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    input_shape = (xs_train.shape[1], xs_train.shape[2])\n",
    "\n",
    "    for layer_config in model_config['lstm_layers']:\n",
    "        model.add(LSTM(layer_config['units'], return_sequences=layer_config['return_sequences'], input_shape=input_shape if 'input_shape' not in layer_config else None))\n",
    "        input_shape = None  # For subsequent layers, input_shape is not required\n",
    "\n",
    "    model.add(Dense(num_target_features))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    # Define the early stopping and model checkpoint callbacks\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "    checkpoint = ModelCheckpoint(path_to_save_model, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "    history = model.fit(xs_train, ys_train, epochs=model_config.get('epochs', 50), batch_size=model_config.get('batch_size', 32), callbacks=[early_stopping, checkpoint])\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length, forecast_horizon, target_col):\n",
    "    target_col_index = target_col\n",
    "    xs, ys = [], []\n",
    "    target_col_name = data.columns[target_col_index]  \n",
    "    for i in range(len(data) - seq_length - forecast_horizon + 1):\n",
    "        x = data.iloc[i:(i + seq_length)].values\n",
    "      #  x = data.iloc[i:(i + seq_length)].drop(columns=[target_col_name]).values \n",
    "        y = data.iloc[(i + seq_length):(i + seq_length + forecast_horizon), target_col].values\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "#data_df = pd.read_csv('../../data/processed/actuals_data.csv', parse_dates=['Time'], index_col='Time')\n",
    "# Dataset with actual weather variables\n",
    "# data_df = pd.read_csv('../data/interim/precovid-data/train/load_with_actual_weather_variables_dataset.csv', parse_dates=['Time'], index_col='Time')\n",
    "\n",
    "# Dataset with forecasted weather variables\n",
    "data_df = pd.read_csv('../data/interim/precovid-data/train/load_with_forecasted_weather_variables_dataset.csv', parse_dates=['Time'], index_col='Time')\n",
    "coloumns_to_drop  = ['Pressure_kpa','Cloud Cover (%)','Wind Direction (deg)','Wind Speed (kmh)']\n",
    "data_df = data_df.drop(columns=coloumns_to_drop)\n",
    "\n",
    "#data preprocessing\n",
    "hour_of_day_col = data_df.index.hour\n",
    "data_df['hour_of_day_sin'] = np.sin(2 * np.pi * hour_of_day_col / 24)\n",
    "data_df['hour_of_day_cos'] = np.cos(2 * np.pi * hour_of_day_col / 24)\n",
    "\n",
    "load_col = data_df.pop('Load (kW)')\n",
    "data_df['Load (kW)'] = load_col\n",
    "\n",
    "target_col = (data_df.columns.get_loc('Load (kW)'))\n",
    "num_target_features = 1\n",
    "scaler_num_features = data_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature (C)</th>\n",
       "      <th>hour_of_day_sin</th>\n",
       "      <th>hour_of_day_cos</th>\n",
       "      <th>Load (kW)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-03-18 00:00:00</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.031472e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-18 01:00:00</th>\n",
       "      <td>14</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>1.007206e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-18 02:00:00</th>\n",
       "      <td>14</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>9.861084e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-18 03:00:00</th>\n",
       "      <td>14</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>9.707610e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-18 04:00:00</th>\n",
       "      <td>14</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>9.622584e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17 04:00:00</th>\n",
       "      <td>8</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>9.767850e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17 05:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>9.912850e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17 06:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>1.025285e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17 07:00:00</th>\n",
       "      <td>6</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>1.077785e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-17 08:00:00</th>\n",
       "      <td>8</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>1.151785e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24849 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Temperature (C)  hour_of_day_sin  hour_of_day_cos  \\\n",
       "Time                                                                     \n",
       "2017-03-18 00:00:00               14         0.000000     1.000000e+00   \n",
       "2017-03-18 01:00:00               14         0.258819     9.659258e-01   \n",
       "2017-03-18 02:00:00               14         0.500000     8.660254e-01   \n",
       "2017-03-18 03:00:00               14         0.707107     7.071068e-01   \n",
       "2017-03-18 04:00:00               14         0.866025     5.000000e-01   \n",
       "...                              ...              ...              ...   \n",
       "2020-01-17 04:00:00                8         0.866025     5.000000e-01   \n",
       "2020-01-17 05:00:00                6         0.965926     2.588190e-01   \n",
       "2020-01-17 06:00:00                6         1.000000     6.123234e-17   \n",
       "2020-01-17 07:00:00                6         0.965926    -2.588190e-01   \n",
       "2020-01-17 08:00:00                8         0.866025    -5.000000e-01   \n",
       "\n",
       "                        Load (kW)  \n",
       "Time                               \n",
       "2017-03-18 00:00:00  1.031472e+06  \n",
       "2017-03-18 01:00:00  1.007206e+06  \n",
       "2017-03-18 02:00:00  9.861084e+05  \n",
       "2017-03-18 03:00:00  9.707610e+05  \n",
       "2017-03-18 04:00:00  9.622584e+05  \n",
       "...                           ...  \n",
       "2020-01-17 04:00:00  9.767850e+05  \n",
       "2020-01-17 05:00:00  9.912850e+05  \n",
       "2020-01-17 06:00:00  1.025285e+06  \n",
       "2020-01-17 07:00:00  1.077785e+06  \n",
       "2020-01-17 08:00:00  1.151785e+06  \n",
       "\n",
       "[24849 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Scale data\n",
    "scaler = MinMaxScaler()\n",
    "data_df_scaled = pd.DataFrame(scaler.fit_transform(data_df), columns=data_df.columns, index=data_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Temperature (C)', 'hour_of_day_sin', 'hour_of_day_cos',\n",
       "       'Load (kW)'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/scalers/scaler.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the scaler to a file using joblib\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../models/scalers/scaler.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[0;32m--> 552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/scalers/scaler.joblib'"
     ]
    }
   ],
   "source": [
    "# Save the scaler to a file using joblib\n",
    "dump(scaler, '../models/scalers/scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2. Create sequences pairs of input and output\n",
    "#In this case we have to configure the target_col-1 to be the index of the target column in the data_df in order to assign in the ys variable\n",
    "# and have input output pairs of sequences\n",
    "seq_length = 2\n",
    "forecast_horizon = 1\n",
    "xs, ys = create_sequences(data_df_scaled, seq_length, forecast_horizon, target_col)\n",
    "print(xs.shape, ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Split data\n",
    "train_size = 0.7\n",
    "num_samples = len(xs)\n",
    "train_end = int(num_samples * train_size)\n",
    "\n",
    "xs_train = xs[:train_end]\n",
    "ys_train = ys[:train_end]\n",
    "xs_test = xs[train_end:]\n",
    "ys_test = ys[train_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Define the model configuration\n",
    "model_config = {\n",
    "    'lstm_layers': [\n",
    "        {'units': 64, 'return_sequences': True},\n",
    "        {'units': 32, 'return_sequences': True},\n",
    "        {'units': 16, 'return_sequences': False}\n",
    "    ],\n",
    "    'epochs': 300,\n",
    "    'batch_size': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Build, train, and evaluate the model\n",
    "multivariate_load_foreacasting_load_temp_included_model_path = '../models/multivariate_load_foreacasting_load_temp_included_model.keras'\n",
    "num_target_features = 1 # The number of output features for the model only load for now\n",
    "model, history = build_and_train_model(\n",
    "    xs_train, ys_train, model_config, num_target_features, path_to_save_model = multivariate_load_foreacasting_load_temp_included_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.evaluate(xs_test, ys_test)\n",
    "print(f'Test Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Build, train, and evaluate the model\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions_scaled = model.predict(xs_test) # contains only load\n",
    "predictions_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale the predictions and actual values\n",
    "# predictions=> contains values for target column (Load)\n",
    "# but our scaler was trained on all columns so we have to inverse transform all columns\n",
    "# so we need to padd with zeros the other columns\n",
    "num_of_missing_training_features = data_df.shape[1] - num_target_features\n",
    "\n",
    "padding_for_missing_training_features = np.zeros((predictions_scaled.shape[0], num_of_missing_training_features))\n",
    "data_to_be_invert_from_scaling = np.hstack([padding_for_missing_training_features, predictions_scaled])\n",
    "data_to_be_invert_from_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_be_invert_from_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model outputs \n",
    "predictions= scaler.inverse_transform(data_to_be_invert_from_scaling)[:, target_col]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_for_missing_training_features = np.zeros((ys_test.shape[0], num_of_missing_training_features))\n",
    "ys_test_scaled = np.hstack([padding_for_missing_training_features, ys_test])\n",
    "ys_test_scaled\n",
    "ys_test = scaler.inverse_transform(ys_test_scaled)[:,target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(ys_test-predictions)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Plot the results\n",
    "test_index = data_df.index[-len(xs_test):]\n",
    "hours_to_plot = 24*14 # Approximately one month\n",
    "\n",
    "plot_results(test_index, ys_test, predictions, hours_to_plot=hours_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_from_to(test_index, ys_test, predictions,'2019-06-01', '2019-07-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your test_index, ys_test_rescaled, and predictions_rescaled already defined\n",
    "plot_seasonal_comparison(test_index, ys_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your test_index, ys_test_rescaled, and predictions_rescaled already defined\n",
    "plot_monthly_comparison(test_index, ys_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your test_index, ys_test_rescaled, and predictions_rescaled already defined\n",
    "plot_weekday_comparison(test_index, ys_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hourly_comparison(test_index, ys_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
